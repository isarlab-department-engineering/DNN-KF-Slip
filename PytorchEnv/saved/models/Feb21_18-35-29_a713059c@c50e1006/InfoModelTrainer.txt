
########################################################################################################################
# TRAINING PARAMETERS AND TRAINING
########################################################################################################################

# Load NN
input_dim = 100
output_dim = 1
model = Med2021(input_size=input_dim, output_size=output_dim)
model.to(device)
learning_rate = 0.001
num_epochs = 100
save_epoch_interval = 10
alpha_decay = 0.0001
# loss, optimizer
criterion = nn.MSELoss()
#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True,
   #                         weight_decay=learning_rate*alpha_decay)
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=learning_rate*alpha_decay )


######################################################################################################################


# COMPARABILE CON LA VECCHIA RETE DI SCKITLEARN
class Med2021(BaseModel):
    def __init__(self, input_size, output_size):
        super().__init__()
        self.fc1 = nn.Linear(input_size, 250)
        self.fc2 = nn.Linear(250, 250)
        self.fc3 = nn.Linear(250, output_size)
        self.dropout_1 = nn.Dropout(p=0.075)
        self.dropout_2 = nn.Dropout(p=0.075)


    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = self.dropout_1(x)
        x = F.relu(self.fc2(x))
        x = self.dropout_2(x)
        x = self.fc3(x)
        return x